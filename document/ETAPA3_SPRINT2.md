# ü§ñ Etapa 3 ‚Äì Constru√ß√£o do Modelo de IA

## 1Ô∏è‚É£ Sele√ß√£o do Modelo

Para o desenvolvimento do modelo de previs√£o da produtividade agr√≠cola da cana-de-a√ß√∫car, avaliamos algoritmos de aprendizado de m√°quina adequados para dados tabulares multivariados e que pudessem se beneficiar do uso de **GPU com CUDA**.

### üéØ Requisitos t√©cnicos considerados:

- Dados de entrada com m√∫ltiplas vari√°veis num√©ricas mensais (NDVI, chuva, temperatura, m√™s).
- Quantidade moderada de dados (n√£o massivos, mas com sazonalidade importante).
- Modelo com **baixo tempo de treinamento** e **capacidade de capturar rela√ß√µes n√£o-lineares** entre clima, vegeta√ß√£o e produtividade.
- Possibilidade de execu√ß√£o acelerada por **GPU NVIDIA com CUDA**, dispon√≠vel em nossa infraestrutura com WSL2.

---

## üîç Modelo escolhido: **XGBoost com acelera√ß√£o por GPU**

Selecionamos o algoritmo **XGBoost Regressor** com o par√¢metro `tree_method='gpu_hist'`, que permite:

- Treinamento extremamente r√°pido utilizando n√∫cleos CUDA;
- Performance compar√°vel ou superior ao Random Forest em muitos cen√°rios com poucos dados;
- Capacidade de realizar **interpreta√ß√£o dos resultados** por meio da import√¢ncia das vari√°veis.

### ‚öôÔ∏è Configura√ß√£o inicial do modelo:

```python
from xgboost import XGBRegressor

modelo = XGBRegressor(
    tree_method='gpu_hist',    # Ativa o uso da GPU (via CUDA)
    n_estimators=200,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)


## 2Ô∏è‚É£ Treinamento e Avalia√ß√£o do Modelo

Com o modelo XGBoost configurado para utilizar **acelera√ß√£o via GPU (CUDA)**, realizamos o treinamento utilizando os dados hist√≥ricos de NDVI, clima e produtividade.

---

### üîÄ Divis√£o dos dados

A base consolidada foi dividida em dois subconjuntos:

- **80% dos dados** para treinamento (`X_train`, `y_train`)
- **20% dos dados** para teste e valida√ß√£o do modelo (`X_test`, `y_test`)

```python
from sklearn.model_selection import train_test_split

X = df[['NDVI', 'Chuva (mm)', 'Temp. M√°x. (C)', 'Temp. M√≠n. (C)', 'Mes']]
y = df['Produtividade (ton/ha)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


## üìä Comparativo entre Modelos: XGBoost vs SVR

Testamos dois algoritmos para prever a produtividade da cana-de-a√ß√∫car:

| Modelo     | MAE (ton/ha) | MSE | R¬≤ (Coef. Determina√ß√£o) |
|------------|--------------|-----|--------------------------|
| XGBoost GPU| 1.22         | 2.08| **-0.53**                |
| SVR (RBF)  | **1.08**     | **1.37** | **-0.01**           |

‚úÖ **O modelo SVR apresentou melhor desempenho** geral, com menor erro absoluto e quadr√°tico.  
üìâ O R¬≤ ainda est√° abaixo de zero, indicando que o modelo n√£o generaliza bem, mas √© **muito superior ao XGBoost neste cen√°rio de poucos dados com baixa varia√ß√£o**.

---

### üéØ Justificativa da Escolha do SVR

O **SVR com kernel RBF** foi escolhido por sua capacidade de lidar com:

- Pequenas bases de dados;
- Rela√ß√µes n√£o lineares entre as vari√°veis clim√°ticas e a produtividade;
- Robustez contra overfitting em datasets com pouca variabilidade.

Al√©m disso, o uso de `StandardScaler` para normaliza√ß√£o das vari√°veis foi essencial para que o SVR tivesse bom desempenho.

---

### üìà Visualiza√ß√µes

- **Gr√°fico Real vs Previsto (SVR)**: mostra boa tend√™ncia de ajuste mesmo com dados limitados.
- Arquivo salvo: `../tests/images/svr_real_vs_prevista.png`


## üß† Etapa 3 ‚Äì Constru√ß√£o e Avalia√ß√£o dos Modelos

Durante a Sprint 2, testamos diferentes algoritmos de regress√£o para prever a produtividade agr√≠cola da cana-de-a√ß√∫car, utilizando dados clim√°ticos e NDVI mensal da regi√£o de Uberaba/MG.

### ‚öôÔ∏è Modelos Avaliados

| Modelo                         | MAE (ton/ha) | MSE  | R¬≤    | Observa√ß√µes |
|-------------------------------|--------------|------|--------|-------------|
| **SVR (RBF)**                 | **1.08**     | **1.37** | **-0.01** | Melhor desempenho geral |
| SVR + valida√ß√£o cruzada + features derivadas | 1.07 | 1.39 | -0.02 | Piorou; valida√ß√£o cruzada inst√°vel |
| SVR otimizado (GridSearch)    | 1.39         | 2.49 | -0.83 | Desempenho inferior |
| **Regress√£o Linear**          | 1.17         | 1.65 | -0.21 | Usado como baseline |

---

### ‚úÖ Justificativa da Escolha Final

Ap√≥s testar v√°rias estrat√©gias ‚Äî incluindo tuning de hiperpar√¢metros, valida√ß√£o cruzada, cria√ß√£o de vari√°veis derivadas e an√°lise de res√≠duos ‚Äî o **modelo SVR com kernel RBF e configura√ß√£o padr√£o** apresentou o melhor equil√≠brio entre simplicidade e desempenho.

- O SVR capturou **rela√ß√µes n√£o-lineares** entre as vari√°veis.
- Tentativas de otimiza√ß√£o autom√°tica (com GridSearchCV) e adi√ß√£o de novas features **n√£o trouxeram ganho real** e inclusive pioraram a performance.
- A regress√£o linear foi √∫til como benchmark, mas teve menor capacidade de generaliza√ß√£o.

---

### üìÅ Gr√°ficos Gerados

- `svr_real_vs_prevista.png` ‚Äì Desempenho do SVR
- `regressao_linear_real_vs_prevista.png` ‚Äì Desempenho do baseline
- `svr_residuos.png` (vers√£o intermedi√°ria) ‚Äì An√°lise de res√≠duos
- `svr_metricas.csv` ‚Äì Registro das m√©tricas principais

---

### üìù Conclus√£o

> O modelo **SVR com RBF** ser√° mantido como modelo oficial do projeto, com base em evid√™ncias estat√≠sticas, robustez e capacidade de aprendizado sobre os dados dispon√≠veis.



## üß† Etapa 3 ‚Äì Constru√ß√£o do Modelo de IA

### üéØ Objetivo
Desenvolver um modelo preditivo capaz de estimar a produtividade agr√≠cola com base nos dados clim√°ticos e no √≠ndice NDVI.

---

### ‚úÖ O que foi feito:

1. **Sele√ß√£o do Modelo**
   - Foram testados diversos algoritmos:
     - SVR (RBF) ‚úÖ (modelo escolhido)
     - XGBoost com GPU
     - Regress√£o Linear (baseline)
   - O SVR se mostrou mais robusto e adaptado ao tamanho e comportamento do dataset.

2. **Treinamento e Valida√ß√£o**
   - Utilizamos `train_test_split` para treinar e testar os modelos.
   - M√©tricas de avalia√ß√£o: `MAE`, `MSE`, `R¬≤`.
   - Visualiza√ß√µes com gr√°ficos de previs√µes e res√≠duos.

3. **Ajuste de Hiperpar√¢metros**
   - Foram testadas abordagens com `GridSearchCV`, valida√ß√£o cruzada (5-fold) e adi√ß√£o de novas vari√°veis.
   - Essas abordagens n√£o trouxeram ganhos reais e foram descartadas ap√≥s an√°lise.
   - O modelo SVR com configura√ß√£o padr√£o foi mantido como o melhor candidato.

---

### üß™ Conclus√£o da Etapa 3

O modelo **SVR com kernel RBF** foi mantido como oficial por apresentar o melhor desempenho, simplicidade e estabilidade frente aos demais avaliados. As tentativas de ajuste mais agressivas (como GridSearch) mostraram-se ineficazes para o volume de dados dispon√≠vel.
